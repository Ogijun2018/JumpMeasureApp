//
//  MainViewModel.swift
//  JumpMeasureApp
//
//  Created by jun.ogino on 2024/08/06.
//

import UIKit
import AVFoundation

class MainViewModel {
    
    enum CameraMode {
        case teleWide
        case wideUltraWide
    }

    @Published var cameraMode: CameraMode = .teleWide
    @Published var teleWideButtonIsHidden = true
    @Published var wideUltraWideButtonIsHidden = true
    @Published var isLoading: Bool = true
    @Published var matchFeaturesImage: UIImage?
    @Published var adjustedImages: [UIImage]?

    private var ciImages: [CIImage] = []
    private var isAuthorized: Bool {
        get async {
            let status = AVCaptureDevice.authorizationStatus(for: .video)
            var isAuthorized = status == .authorized
            if status == .notDetermined {
                isAuthorized = await AVCaptureDevice.requestAccess(for: .video)
            }
            return isAuthorized
        }
    }

    // MARK: public func
    func removeCiImages() {
        ciImages.removeAll()
    }

    func appendCiImage(image: CIImage) {
        ciImages.append(image)

        // ciImagesãŒ2æšã«ãªã£ãŸã‚‰ç”»åƒã®calibrationã‚’è¡Œã„ã€ç‰¹å¾´ç‚¹ã‚’è¨ˆç®—ã—ãŸç”»åƒã‚’æ›´æ–°ã™ã‚‹
        if ciImages.count >= 2 {
            // ç”»åƒã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†
            let (images, scaleFactor) = calibrateImages()
            // 2ã¤ã®ç”»åƒã‚’åŒã˜å€ç‡ã«å¤‰æ›´ã™ã‚‹
            // calibrateImagesã§è¿”ã£ã¦ãã‚‹imagesã¯å¿…ãš1ç•ªç›®ã®ç„¦ç‚¹è·é›¢ã®ã»ã†ãŒçŸ­ã„
            guard let images, let adjustedImages = adjustImagesToSameScale(images: images, scaleFactor: scaleFactor),
                  // ç‰¹å¾´ç‚¹ã‚ã‚Šã®ç”»åƒ
                  let matchFeaturesImage = ImageProcessor.matchFeaturesBetweenImage(adjustedImages[0],
                                                                                    andImage: adjustedImages[1]) else { return }
            self.matchFeaturesImage = matchFeaturesImage
            self.adjustedImages = adjustedImages
        }
    }

    func updateCameraMode(mode: CameraMode) {
        Task {
            isLoading = true
            try await self.sleepTask()
            if await self.isAuthorized {
                cameraMode = mode
            } else {
                print("æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“")
            }
            try await self.sleepTask()
            isLoading = false
        }
    }

    func saveButtonDidTap(completion: (UIImage, UIImage, UIImage) -> Void) {
        guard let shortFocalImage = adjustedImages?[0],
              let longFocalImage = adjustedImages?[1],
              let matchFeaturesImage else { return }
        completion(matchFeaturesImage, shortFocalImage, longFocalImage)
    }

    // MARK: - private func
    private func sleepTask() async throws {
        do {
            try await Task.sleep(nanoseconds: 500_000_000) // wait for 0.5s
        } catch {
            print(error.localizedDescription)
        }
    }

    private func calibrateImages() -> ([UIImage]?, CGFloat?){
        guard let firstFocalLength = getFocalLength(from: ciImages[0]),
              let secondFocalLength = getFocalLength(from: ciImages[1]),
              let firstUIImage = ciImages[0].toUIImage(orientation: .up),
              let secondUIImage = ciImages[1].toUIImage(orientation: .up) else {
            return (nil, nil)
        }

        switch cameraMode {
        case .teleWide:
            // ç„¦ç‚¹è·é›¢ãŒçŸ­ã„æ–¹ãŒåºƒè§’ã‚«ãƒ¡ãƒ©
            if firstFocalLength <= secondFocalLength {
                // firstUIImageãŒåºƒè§’ã®å ´åˆ
                guard let wide = ImageProcessor.undistortion(from: firstUIImage, imageParam: Constant.wideCameraParameter),
                      let telephoto = ImageProcessor.undistortion(from: secondUIImage, imageParam: Constant.telephotoCameraParameter) else { return (nil, nil) }
                return ([wide, telephoto], secondFocalLength/firstFocalLength)
            } else {
                // secondUIImageãŒåºƒè§’ã®å ´åˆ
                guard let telephoto = ImageProcessor.undistortion(from: firstUIImage, imageParam: Constant.telephotoCameraParameter),
                      let wide = ImageProcessor.undistortion(from: secondUIImage, imageParam: Constant.wideCameraParameter) else { return (nil, nil) }
                return ([wide, telephoto], firstFocalLength/secondFocalLength)
            }
        case .wideUltraWide:
            // ç„¦ç‚¹è·é›¢ãŒçŸ­ã„æ–¹ãŒè¶…åºƒè§’ã‚«ãƒ¡ãƒ©
            if firstFocalLength <= secondFocalLength {
                // firstUIImageãŒè¶…åºƒè§’ã®å ´åˆ
                guard let ultraWide = ImageProcessor.undistortion(from: firstUIImage, imageParam: Constant.ultraWideCameraParameter),
                      let wide = ImageProcessor.undistortion(from: secondUIImage, imageParam: Constant.wideCameraParameter) else { return (nil, nil) }
                return ([ultraWide, wide], secondFocalLength/firstFocalLength)
            } else {
                // secondUIImageãŒè¶…åºƒè§’ã®å ´åˆ
                guard let wide = ImageProcessor.undistortion(from: firstUIImage, imageParam: Constant.wideCameraParameter),
                      let ultraWide = ImageProcessor.undistortion(from: secondUIImage, imageParam: Constant.ultraWideCameraParameter) else { return (nil, nil) }
                return ([ultraWide, wide], firstFocalLength/secondFocalLength)
            }
        }
    }

    /// EXIFãƒ‡ãƒ¼ã‚¿ã‹ã‚‰35mmæ›ç®—ã®ç„¦ç‚¹è·é›¢ã‚’å–å¾—
    private func getFocalLength(from image: CIImage) -> CGFloat? {
        guard let exifDict = image.properties[kCGImagePropertyExifDictionary as String] as? [String: Any],
              let focalLength = exifDict[kCGImagePropertyExifFocalLenIn35mmFilm as String] as? CGFloat
        else { return nil }
        print("ğŸš§ focalLength \(focalLength)")
        return focalLength
    }

    private func trimmingImage(_ image: UIImage, trimmingArea: CGRect) -> UIImage? {
        guard let croppedImage = image.cgImage?.cropping(to: trimmingArea) else {
            return nil
        }
        return .init(cgImage: croppedImage, scale: image.scale, orientation: image.imageOrientation)
    }

    // ç„¦ç‚¹è·é›¢ã®ç•°ãªã‚‹äºŒã¤ã®ç”»åƒã‚’åŒã˜å€ç‡ã«å¤‰æ›´ã™ã‚‹
    private func adjustImagesToSameScale(images: [UIImage]?, scaleFactor: CGFloat?) -> [UIImage]? {
        guard let shortFocalImage = images?[0],
              let longFocalImage = images?[1],
              let scaleFactor else { return nil }

        let croppedWidth = shortFocalImage.size.width / (scaleFactor / 1.08)
        let croppedHeight = shortFocalImage.size.height / (scaleFactor / 1.08)
        print(shortFocalImage.size, croppedWidth, croppedHeight)
        // ç„¦ç‚¹è·é›¢ã®çŸ­ã„æ–¹ã‚’æ‹¡å¤§ã—ã€ç„¦ç‚¹è·é›¢ã®é•·ã„æ–¹ã«åˆã‚ã›ã‚‹
        let cropRect = CGRect(
            x: (shortFocalImage.size.width - croppedWidth) / 2 - 110,
            y: (shortFocalImage.size.height - croppedHeight) / 2 - 40,
            width: croppedWidth,
            height: croppedHeight
        )

        guard let croppedImage = shortFocalImage.cgImage?.cropping(to: cropRect) else { return nil }
        let scaledImage = UIImage(cgImage: croppedImage, scale: shortFocalImage.scale, orientation: shortFocalImage.imageOrientation)

        // æ‹¡å¤§ã—ãŸç„¦ç‚¹è·é›¢ã®çŸ­ã„ç”»åƒã®ç”»åƒã‚µã‚¤ã‚ºã‚’ç„¦ç‚¹è·é›¢ã®é•·ã„ç”»åƒã®ç”»åƒã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹
        // MEMO: resizedSizeã‚’longForcalImage.size.widthã¨ã™ã‚‹ã¨scaledImageãŒ 5760x3240 ã®ç”»åƒã«ãªã£ã¦ã—ã¾ã£ãŸ
        // 1920x1080ã«åˆã‚ã›ã‚‹ãŸã‚ã€1/3ã®CGSizeã‚’æŒ‡å®šã—ã¦ã„ã‚‹
        let resizedSize = CGSize(width: longFocalImage.size.width/3, height: longFocalImage.size.height/3)
        UIGraphicsBeginImageContextWithOptions(resizedSize, false, 0.0)
        scaledImage.draw(in: CGRect(origin: .zero, size: resizedSize))
        guard let resizedImage = UIGraphicsGetImageFromCurrentImageContext() else { return nil }

        return [resizedImage, longFocalImage]
    }

}
